{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b36f46-d6bc-4581-899a-fa8d26fcd390",
   "metadata": {},
   "source": [
    "# Phrases\n",
    "\n",
    "Process the phrases that appear in a relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d0a2ff-aa89-462a-b714-22f7dd45f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0331f1bd-85e7-417d-b5e7-a656ae6c4e96",
   "metadata": {},
   "source": [
    "## 1. Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264cfc81-f029-4b36-a957-c2ca1fd1c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"../data/femke.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775c6f98-a64a-4c47-949b-abbf60870e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = []\n",
    "infile = open(DATA_FILE, \"r\")\n",
    "for line in infile:\n",
    "    json_data.append(json.loads(line))\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "426684f2-2450-4945-9be1-2cf22f398cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1867"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2eb4bd-67f3-47c6-a524-4630aee9ae4e",
   "metadata": {},
   "source": [
    "## 2. Give an example of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d2e1f8-82cf-4e04-8c53-f01548c25616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 6660,\n",
       " 'data': 'Today I want to send a clear message to the people of this great country, of Greece. I know that many people feel without hope. Many are making extremely difficult sacrifices. And many people ask why they should do more. I understand those concerns. And I agree that some of the efforts seem unfair. But I ask people to recognise the other alternatives which will be much more difficult for Greece and will affect even more the most vulnerable in the Greek society. So this is why it is the right approach to ask Greece to reform, to increase its competitiveness to have a viable future, irrespective of the crisis. You, in Greece, with our support, need to rebuild your country, your structures, your administration, your economy to increase the competitiveness of Greece. And the best hope of a return to growth and job creation is inside the euro area. Staying in the euro is the best chance to avoid worse hardship and difficulties to the Greek people, namely for those in a more vulnerable position',\n",
       " 'label': [[734, 772, 'Content_Concept_2'],\n",
       "  [731, 733, 'Content_Relation_Explanation'],\n",
       "  [616, 678, 'Content_Concept_1']],\n",
       " 'source_id': 3487,\n",
       " 'speech_id': 536,\n",
       " 'paragraph_id': '1-2',\n",
       " 'missing concept 1': 'you in Greece, with out support, you need to rebuild your country'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2828f6-6246-475b-abb0-a4a2df26caf7",
   "metadata": {},
   "source": [
    "## 3. Count the frequency of the labels in each data item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b6a32b-980b-4ec7-9efe-2a3f88bcf594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1 1 1': 1400, '2 1 1': 230, '1 1 2': 136, '2 1 2': 24, '1 2 1': 2, '1 0 0': 3, '1 1 0': 5, '0 1 1': 5, '3 1 1': 30, '1 1 3': 13, '2 1 0': 3, '4 1 1': 4, '0 1 3': 1, '3 1 2': 3, '2 1 3': 3, '5 1 1': 1, '1 1 4': 1, '4 1 2': 3}\n"
     ]
    }
   ],
   "source": [
    "def get_patterns(json_data):\n",
    "    base_cases = []\n",
    "    results = {}\n",
    "    for data in json_data:\n",
    "        key = [0, 0, 0]\n",
    "        for label in data[\"label\"]:\n",
    "            if label[2] == 'Content_Concept_1':\n",
    "                key[0] += 1\n",
    "            elif label[2] == 'Content_Relation_Explanation':\n",
    "                key[1] += 1\n",
    "            elif label[2] == 'Content_Concept_2':\n",
    "                key[2] += 1\n",
    "            else:\n",
    "                print(\"cannot happen\")\n",
    "        for i in range(0, len(key)):\n",
    "            key[i] = str(key[i])\n",
    "        results_key = \" \".join(key)\n",
    "        if not results_key in results:\n",
    "            results[results_key] = 1\n",
    "        else:\n",
    "            results[results_key] += 1\n",
    "        if results_key == \"1 1 1\":\n",
    "             base_cases.append(data)\n",
    "    return [results, base_cases]\n",
    "\n",
    "results, base_cases = get_patterns(json_data)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dc8213-d58d-4600-ab5f-4ea454ea275d",
   "metadata": {},
   "source": [
    "Some data items have more than two content concepts because of split phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf504fc9-f8bd-4545-81b4-04e57197b647",
   "metadata": {},
   "source": [
    "## 4. Convert base cases (1,1,1) to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "666fbd9d-a75c-4d69-8072-0b5a23565557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d49fae2c-8bce-4508-a1b2-946ddfede36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 6660,\n",
       " 'data': 'Today I want to send a clear message to the people of this great country, of Greece. I know that many people feel without hope. Many are making extremely difficult sacrifices. And many people ask why they should do more. I understand those concerns. And I agree that some of the efforts seem unfair. But I ask people to recognise the other alternatives which will be much more difficult for Greece and will affect even more the most vulnerable in the Greek society. So this is why it is the right approach to ask Greece to reform, to increase its competitiveness to have a viable future, irrespective of the crisis. You, in Greece, with our support, need to rebuild your country, your structures, your administration, your economy to increase the competitiveness of Greece. And the best hope of a return to growth and job creation is inside the euro area. Staying in the euro is the best chance to avoid worse hardship and difficulties to the Greek people, namely for those in a more vulnerable position',\n",
       " 'label': [[734, 772, 'Content_Concept_2'],\n",
       "  [731, 733, 'Content_Relation_Explanation'],\n",
       "  [616, 678, 'Content_Concept_1']],\n",
       " 'source_id': 3487,\n",
       " 'speech_id': 536,\n",
       " 'paragraph_id': '1-2',\n",
       " 'missing concept 1': 'you in Greece, with out support, you need to rebuild your country'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_cases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "317d0cc7-d5fd-48fc-8b72-27a3c5ce77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "for data_in in base_cases:\n",
    "    data_out = [data_in[\"data\"], \"\", \"\", \"\"]\n",
    "    for label_data in data_in[\"label\"]:\n",
    "        data_out_id = -1\n",
    "        if label_data[2] == 'Content_Concept_1':\n",
    "            data_out_id = 1\n",
    "        elif label_data[2] == 'Content_Relation_Explanation':\n",
    "            data_out_id = 2\n",
    "        elif label_data[2] == 'Content_Concept_2':\n",
    "            data_out_id = 3\n",
    "        else:\n",
    "            print(f\"unexpected label data: {label_data}\")\n",
    "        if data_out[data_out_id] != \"\":\n",
    "            print(\"duplicate data in label_data: {data_in['label']}\")\n",
    "        data_out[data_out_id] = data_in[\"data\"][label_data[0]:label_data[1]]\n",
    "    table.append(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f27dbd16-6532-420b-b33a-17a7a4385321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today I want to send a clear message to the people of this great country, of Greece. I know that many people feel without hope. Many are making extremely difficult sacrifices. And many people ask why they should do more. I understand those concerns. And I agree that some of the efforts seem unfair. But I ask people to recognise the other alternatives which will be much more difficult for Greece and will affect even more the most vulnerable in the Greek society. So this is why it is the right approach to ask Greece to reform, to increase its competitiveness to have a viable future, irrespective of the crisis. You, in Greece, with our support, need to rebuild your country, your structures, your administration, your economy to increase the competitiveness of Greece. And the best hope of a return to growth and job creation is inside the euro area. Staying in the euro is the best chance to avoid worse hardship and difficulties to the Greek people, namely for those in a more vulnerable position',\n",
       " 'You, in Greece, with our support, need to rebuild your country',\n",
       " 'to',\n",
       " 'increase the competitiveness of Greece']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90435022-4734-43e4-b66f-24f229187589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Content_Concept_1</th>\n",
       "      <th>Content_Relation_Explanation</th>\n",
       "      <th>Content_Concept_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today I want to send a clear message to the pe...</td>\n",
       "      <td>You, in Greece, with our support, need to rebu...</td>\n",
       "      <td>to</td>\n",
       "      <td>increase the competitiveness of Greece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today I want to send a clear message to the pe...</td>\n",
       "      <td>You, in Greece, with our support, need to rebu...</td>\n",
       "      <td>And the best hope of a</td>\n",
       "      <td>return to growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To conclude, let me say a few words on the eur...</td>\n",
       "      <td>We have taken important, fundamental decisions</td>\n",
       "      <td>to safeguard</td>\n",
       "      <td>the stability of the euro area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To conclude, let me say a few words on the eur...</td>\n",
       "      <td>We need sustained efforts and determination</td>\n",
       "      <td>As we said there will not be</td>\n",
       "      <td>magic solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Giving to the ECB the ultimate responsibility ...</td>\n",
       "      <td>confidence between the banks</td>\n",
       "      <td>and in this way</td>\n",
       "      <td>increase the financial stability in the euro area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>But today I want to focus on our economic prio...</td>\n",
       "      <td>cut business taxes</td>\n",
       "      <td>You've got to</td>\n",
       "      <td>succeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>But today I want to focus on our economic prio...</td>\n",
       "      <td>tackle the bloat in welfare</td>\n",
       "      <td>You've got to</td>\n",
       "      <td>succeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>But today I want to focus on our economic prio...</td>\n",
       "      <td>make sure your schools and your universities a...</td>\n",
       "      <td>and crucially you've got to</td>\n",
       "      <td>succeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>Now yesterday I gave a speech setting out the ...</td>\n",
       "      <td>When you have a single currency</td>\n",
       "      <td>you move inexorably towards</td>\n",
       "      <td>a banking union</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>Now yesterday I gave a speech setting out the ...</td>\n",
       "      <td>When you have a single currency</td>\n",
       "      <td>you move inexorably towards</td>\n",
       "      <td>forms of fiscal union</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Paragraph  \\\n",
       "0     Today I want to send a clear message to the pe...   \n",
       "1     Today I want to send a clear message to the pe...   \n",
       "2     To conclude, let me say a few words on the eur...   \n",
       "3     To conclude, let me say a few words on the eur...   \n",
       "4     Giving to the ECB the ultimate responsibility ...   \n",
       "...                                                 ...   \n",
       "1395  But today I want to focus on our economic prio...   \n",
       "1396  But today I want to focus on our economic prio...   \n",
       "1397  But today I want to focus on our economic prio...   \n",
       "1398  Now yesterday I gave a speech setting out the ...   \n",
       "1399  Now yesterday I gave a speech setting out the ...   \n",
       "\n",
       "                                      Content_Concept_1  \\\n",
       "0     You, in Greece, with our support, need to rebu...   \n",
       "1     You, in Greece, with our support, need to rebu...   \n",
       "2        We have taken important, fundamental decisions   \n",
       "3           We need sustained efforts and determination   \n",
       "4                          confidence between the banks   \n",
       "...                                                 ...   \n",
       "1395                                 cut business taxes   \n",
       "1396                        tackle the bloat in welfare   \n",
       "1397  make sure your schools and your universities a...   \n",
       "1398                    When you have a single currency   \n",
       "1399                    When you have a single currency   \n",
       "\n",
       "      Content_Relation_Explanation  \\\n",
       "0                               to   \n",
       "1           And the best hope of a   \n",
       "2                     to safeguard   \n",
       "3     As we said there will not be   \n",
       "4                  and in this way   \n",
       "...                            ...   \n",
       "1395                 You've got to   \n",
       "1396                 You've got to   \n",
       "1397   and crucially you've got to   \n",
       "1398   you move inexorably towards   \n",
       "1399   you move inexorably towards   \n",
       "\n",
       "                                      Content_Concept_2  \n",
       "0                increase the competitiveness of Greece  \n",
       "1                                      return to growth  \n",
       "2                        the stability of the euro area  \n",
       "3                                       magic solutions  \n",
       "4     increase the financial stability in the euro area  \n",
       "...                                                 ...  \n",
       "1395                                            succeed  \n",
       "1396                                            succeed  \n",
       "1397                                            succeed  \n",
       "1398                                    a banking union  \n",
       "1399                              forms of fiscal union  \n",
       "\n",
       "[1400 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(table, columns=[\"Paragraph\", \"Content_Concept_1\", \"Content_Relation_Explanation\", \"Content_Concept_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5de83-1ea6-4ee7-b72d-0da9a58df4a4",
   "metadata": {},
   "source": [
    "## 5. Combine all data of duplicate paragraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdc106bb-6da3-430c-ae11-550527b930d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = {}\n",
    "for data in json_data:\n",
    "    key = f\"{data['source_id']} {data['speech_id']} {data['paragraph_id']}\"\n",
    "    if key not in combined_data:\n",
    "        combined_data[key] = copy.deepcopy(data)\n",
    "    else:\n",
    "        if len(data[\"data\"]) != len(combined_data[key][\"data\"]):\n",
    "            print(\"cannot happen\")\n",
    "        for label_data in data[\"label\"]:\n",
    "            if label_data not in combined_data[key][\"label\"]:\n",
    "                combined_data[key][\"label\"].append(label_data)\n",
    "                if combined_data[key][\"label\"][-1][1] > len(combined_data[key][\"data\"]):\n",
    "                    combined_data[key][\"label\"][-1][1] = len(combined_data[key][\"data\"])\n",
    "\n",
    "for key in combined_data:\n",
    "    for label_data in combined_data[key][\"label\"]:\n",
    "        label_data.append(combined_data[key][\"data\"][label_data[0]:label_data[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "098760d4-a38b-4ba8-8150-c87ab4b5dde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ca54a8b-7175-4588-a109-b1b9b4affb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'5 2 4': 3, '2 2 2': 52, '1 1 1': 95, '3 2 3': 10, '3 2 2': 24, '5 3 3': 3, '5 2 2': 6, '5 4 6': 5, '4 3 3': 5, '1 2 2': 5, '8 2 4': 1, '2 3 3': 1, '8 5 8': 1, '2 1 1': 30, '1 1 2': 22, '3 3 3': 15, '2 1 2': 8, '9 5 6': 1, '3 3 4': 8, '3 1 2': 5, '2 2 6': 4, '4 2 2': 11, '3 1 1': 12, '4 2 3': 8, '8 3 4': 2, '6 4 4': 3, '2 2 4': 5, '4 1 1': 5, '5 1 1': 4, '14 6 7': 1, '13 4 4': 1, '3 4 4': 2, '1 1 3': 7, '6 2 2': 5, '7 5 5': 2, '4 3 4': 7, '7 4 4': 2, '5 1 2': 1, '2 3 4': 2, '6 4 5': 1, '4 4 4': 5, '3 5 8': 1, '1 3 4': 1, '2 2 3': 9, '6 5 5': 2, '8 5 5': 1, '4 2 1': 2, '7 1 2': 1, '1 1 4': 3, '3 2 5': 2, '6 3 4': 2, '8 3 9': 2, '3 3 5': 1, '6 4 6': 4, '4 2 4': 5, '4 4 5': 1, '10 9 11': 1, '15 11 16': 1, '11 5 6': 1, '1 1 5': 3, '10 3 4': 1, '1 1 8': 1, '8 3 11': 1, '1 2 3': 2, '14 5 9': 1, '3 2 4': 2, '7 5 6': 1, '4 5 6': 1, '7 2 2': 2, '9 4 6': 2, '6 1 1': 2, '4 3 2': 1, '9 4 11': 1, '4 1 3': 3, '2 1 12': 1, '3 1 4': 2, '11 4 6': 1, '3 5 7': 1, '6 3 5': 1, '2 1 5': 1, '4 4 7': 1, '2 2 5': 2, '2 3 5': 2, '11 3 4': 1, '1 2 5': 1, '5 4 4': 3, '5 2 10': 1, '11 7 9': 2, '8 5 7': 1, '4 2 5': 2, '2 1 8': 1, '14 8 14': 1, '14 3 8': 1, '9 7 14': 1, '7 6 8': 1, '10 1 1': 1, '6 5 4': 1, '2 3 9': 1, '5 5 4': 1, '9 5 13': 1, '6 2 6': 1, '6 3 3': 2, '4 1 2': 3, '6 1 3': 1, '6 3 2': 1, '2 4 4': 1, '3 1 3': 2, '10 7 8': 1, '5 3 6': 1, '6 2 5': 1, '5 5 5': 1, '7 3 6': 1, '5 2 6': 1, '15 3 8': 1, '2 1 3': 2, '12 4 6': 1, '5 4 7': 1, '1 2 6': 1, '4 4 6': 1, '4 2 6': 1, '5 5 7': 1, '7 6 10': 1, '14 2 3': 1, '7 5 13': 1, '3 3 2': 1, '11 5 11': 1, '5 3 7': 2, '1 3 3': 1, '5 3 4': 1, '4 2 9': 1, '9 3 3': 1, '7 2 5': 1, '6 2 3': 1}\n"
     ]
    }
   ],
   "source": [
    "results, base_cases = get_patterns(list(combined_data.values()))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01e8e0e8-9aed-4cd4-95f1-27b677aba6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 6660,\n",
       " 'data': 'Today I want to send a clear message to the people of this great country, of Greece. I know that many people feel without hope. Many are making extremely difficult sacrifices. And many people ask why they should do more. I understand those concerns. And I agree that some of the efforts seem unfair. But I ask people to recognise the other alternatives which will be much more difficult for Greece and will affect even more the most vulnerable in the Greek society. So this is why it is the right approach to ask Greece to reform, to increase its competitiveness to have a viable future, irrespective of the crisis. You, in Greece, with our support, need to rebuild your country, your structures, your administration, your economy to increase the competitiveness of Greece. And the best hope of a return to growth and job creation is inside the euro area. Staying in the euro is the best chance to avoid worse hardship and difficulties to the Greek people, namely for those in a more vulnerable position',\n",
       " 'label': [[734,\n",
       "   772,\n",
       "   'Content_Concept_2',\n",
       "   'increase the competitiveness of Greece'],\n",
       "  [731, 733, 'Content_Relation_Explanation', 'to'],\n",
       "  [616,\n",
       "   678,\n",
       "   'Content_Concept_1',\n",
       "   'You, in Greece, with our support, need to rebuild your country'],\n",
       "  [616,\n",
       "   665,\n",
       "   'Content_Concept_1',\n",
       "   'You, in Greece, with our support, need to rebuild'],\n",
       "  [680, 695, 'Content_Concept_1', 'your structures'],\n",
       "  [697, 716, 'Content_Concept_1', 'your administration'],\n",
       "  [718, 730, 'Content_Concept_1', 'your economy'],\n",
       "  [774, 796, 'Content_Relation_Explanation', 'And the best hope of a'],\n",
       "  [797, 813, 'Content_Concept_2', 'return to growth'],\n",
       "  [797, 806, 'Content_Concept_2', 'return to'],\n",
       "  [818, 830, 'Content_Concept_2', 'job creation']],\n",
       " 'source_id': 3487,\n",
       " 'speech_id': 536,\n",
       " 'paragraph_id': '1-2',\n",
       " 'missing concept 1': 'you in Greece, with out support, you need to rebuild your country'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data[list(combined_data.keys())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ad6c2-7207-4ed8-871c-bc58c6a63fb7",
   "metadata": {},
   "source": [
    "## 6. Make character labels\n",
    "\n",
    "Several tokens have more than one label. We use the following labeling scheme:\n",
    "\n",
    "* 1: Content_Concept_1\n",
    "* 2: Content_Concept_2\n",
    "* 3: both Content_Concept_1 and Content_Concept_2\n",
    "* E: Content_Relation_Explanation\n",
    "* F: both Content_Relation_Explanation and Content_Concept_1\n",
    "* G: both Content_Relation_Explanation and Content_Concept_2\n",
    "* \\*: all three labels: Content_Relation_Explanation and Content_Concept_1 and Content_Concept_2\n",
    "* .: no label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59ba21f5-31fb-4a11-88a6-1bc31f517bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Label_Clash:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "        \n",
    "    def add(self, key):\n",
    "        if key not in self.data:\n",
    "            self.data[key] = 1\n",
    "        else:\n",
    "            self.data[key] += 1\n",
    "            \n",
    "    def print(self):\n",
    "        print(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "200a302c-6e67-4e8c-af05-eb55bd33b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_clash = Label_Clash()\n",
    "for key in combined_data:\n",
    "    combined_data[key]['labels'] = len(combined_data[key][\"data\"])*[\".\"]\n",
    "    for label in combined_data[key][\"label\"]:\n",
    "        for i in range(label[0], label[1]):\n",
    "            if label[2] == \"Content_Concept_1\":\n",
    "                if combined_data[key]['labels'][i] != \".\":\n",
    "                    combined_data[key]['labels'][i] = \"1\"\n",
    "                elif combined_data[key]['labels'][i] != \"1\":\n",
    "                    combined_data[key]['labels'][i] = \"1\"\n",
    "                elif combined_data[key]['labels'][i] != \"E\":\n",
    "                    combined_data[key]['labels'][i] = \"F\"\n",
    "                elif combined_data[key]['labels'][i] != \"2\":\n",
    "                    combined_data[key]['labels'][i] = \"3\"\n",
    "                elif combined_data[key]['labels'][i] != \"3\":\n",
    "                    combined_data[key]['labels'][i] = \"3\"\n",
    "                elif combined_data[key]['labels'][i] != \"F\":\n",
    "                    combined_data[key]['labels'][i] = \"F\"\n",
    "                elif combined_data[key]['labels'][i] != \"G\":\n",
    "                    combined_data[key]['labels'][i] = \"*\"\n",
    "                else:\n",
    "                    print(\"cannot happen\")\n",
    "            elif label[2] == \"Content_Relation_Explanation\":\n",
    "                if combined_data[key]['labels'][i] != \".\":\n",
    "                    combined_data[key]['labels'][i] = \"E\"\n",
    "                elif combined_data[key]['labels'][i] != \"1\":\n",
    "                    combined_data[key]['labels'][i] = \"F\"\n",
    "                elif combined_data[key]['labels'][i] != \"E\":\n",
    "                    combined_data[key]['labels'][i] = \"E\"\n",
    "                elif combined_data[key]['labels'][i] != \"2\":\n",
    "                    combined_data[key]['labels'][i] = \"G\"\n",
    "                elif combined_data[key]['labels'][i] != \"3\":\n",
    "                    combined_data[key]['labels'][i] = \"*\"\n",
    "                elif combined_data[key]['labels'][i] != \"F\":\n",
    "                    combined_data[key]['labels'][i] = \"F\"\n",
    "                elif combined_data[key]['labels'][i] != \"G\":\n",
    "                    combined_data[key]['labels'][i] = \"G\"\n",
    "                else:\n",
    "                    print(\"cannot happen\")\n",
    "            elif label[2] == \"Content_Concept_2\":\n",
    "                if combined_data[key]['labels'][i] != \".\":\n",
    "                    combined_data[key]['labels'][i] = \"2\"\n",
    "                elif combined_data[key]['labels'][i] != \"1\":\n",
    "                    combined_data[key]['labels'][i] = \"3\"\n",
    "                elif combined_data[key]['labels'][i] != \"E\":\n",
    "                    combined_data[key]['labels'][i] = \"G\"\n",
    "                elif combined_data[key]['labels'][i] != \"2\":\n",
    "                    combined_data[key]['labels'][i] = \"2\"\n",
    "                elif combined_data[key]['labels'][i] != \"3\":\n",
    "                    combined_data[key]['labels'][i] = \"3\"\n",
    "                elif combined_data[key]['labels'][i] != \"F\":\n",
    "                    combined_data[key]['labels'][i] = \"*\"\n",
    "                elif combined_data[key]['labels'][i] != \"G\":\n",
    "                    combined_data[key]['labels'][i] = \"G\"\n",
    "                else:\n",
    "                    print(\"cannot happen\")\n",
    "            else:\n",
    "                print(f\"unknown label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9608b557-2475-4ca6-9522-e2d93a288e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................11111111111111111111111111111111111111111111111111111111111111..111111111111111..1111111111111111111..111111111111.FF.33333333333333333333333333333333333333..FFFFFFFFFFFFFFFFFFFFFF.2222222223333333.....333333333333.......................................................................................................'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\"\".join(combined_data[list(combined_data.keys())[0]][\"labels\"]))[:933]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad348bdb-0d3e-4b61-8d8c-cd4bd62b5196",
   "metadata": {},
   "source": [
    "## 7. Labels without the Concept information\n",
    "\n",
    "As a first step we could try to find the tokens in the Content Relation Explantion parts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "028015b2-75ab-4613-89d6-ef1068d629cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_key in combined_data:\n",
    "    paragraph = combined_data[data_key][\"data\"]\n",
    "    tokens = {}\n",
    "    token_id = -1\n",
    "    for i in range(0, len(paragraph)):\n",
    "        if token_id < 0 and paragraph[i] == \" \":\n",
    "            next\n",
    "        elif token_id < 0:\n",
    "            token_id = i\n",
    "            tokens[token_id] = paragraph[i]\n",
    "        elif paragraph[i] == \" \":\n",
    "            token_id = -1\n",
    "        elif re.search(\"[.,?!]\", paragraph[i]):\n",
    "            tokens[i] = paragraph[i]\n",
    "        else:\n",
    "            tokens[token_id] += paragraph[i]\n",
    "    labels = {}\n",
    "    for label_key in tokens:\n",
    "        labels[label_key] = \"O\"\n",
    "    for label in combined_data[data_key][\"label\"]:\n",
    "        if label[2] == 'Content_Relation_Explanation':\n",
    "            first = True\n",
    "            for label_key in labels:\n",
    "                if label_key >= label[0] and label_key < label[1]:\n",
    "                    if first:\n",
    "                        labels[label_key] = \"B-E\"\n",
    "                        first = False\n",
    "                    else:\n",
    "                        labels[label_key] = \"I-E\"\n",
    "    combined_data[data_key][\"tokens\"] = [ (tokens[label_key], labels[label_key]) for label_key in labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4103d924-86a4-4f25-ab49-fb6c6554a80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today I want to send a clear message to the people of this great country , of Greece . I know that many people feel without hope . Many are making extremely difficult sacrifices . And many people ask why they should do more . I understand those concerns . And I agree that some of the efforts seem unfair . But I ask people to recognise the other alternatives which will be much more difficult for Greece and will affect even more the most vulnerable in the Greek society . So this is why it is the right approach to ask Greece to reform , to increase its competitiveness to have a viable future , irrespective of the crisis . You , in Greece , with our support , need to rebuild your country , your structures , your administration , your economy ('to', 'B-E') increase the competitiveness of Greece . ('And', 'B-E') ('the', 'I-E') ('best', 'I-E') ('hope', 'I-E') ('of', 'I-E') ('a', 'I-E') return to growth and job creation is inside the euro area . Staying in the euro is the best chance to avoid worse hardship and difficulties to the Greek people , namely for those in a more vulnerable position "
     ]
    }
   ],
   "source": [
    "for pair in combined_data[list(combined_data.keys())[0]][\"tokens\"]:\n",
    "    if pair[1] == 'O':\n",
    "        print(pair[0], end=\" \")\n",
    "    else:\n",
    "        print(str(pair), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c859119-b183-4698-8aed-165502f9300b",
   "metadata": {},
   "source": [
    "## 8. Machine learning starting from Sequence Classification\n",
    "\n",
    "Instructions copied from `filterbubble/transformers/test.ipynb` section `5. BERT Fine-Tuning Tutorial with PyTorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc2d8cfd-e764-4f13-849c-767cde9e1c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForTokenClassification, AdamW, BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5e3083f-73f5-49dc-9801-60532c659f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_labels(predictions):\n",
    "    prediction_labels = []\n",
    "    for i in range(len(predictions)):\n",
    "        prediction_labels.extend(np.argmax(predictions[i], axis=1).flatten())\n",
    "    return prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67354984-ad68-408e-961e-529802f6a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9f51fe1-0bf2-4edf-99d0-cd284799ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e149009e-3dfe-4937-b959-992806b673a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_initial_words(sentence, n):\n",
    "    words = sentence.strip().split()\n",
    "    return \" \".join(words[int(n):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68dda181-a1c0-44a6-ac65-e6a3c1fa777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_labels(true_labels, predictions, sentence_sources, label_values):\n",
    "    prediction_labels = get_prediction_labels(predictions)\n",
    "    true_labels_flattened = []\n",
    "    for array in true_labels:\n",
    "         true_labels_flattened.extend(array)\n",
    "    prediction_labels_collapsed = []\n",
    "    true_labels_collapsed = []\n",
    "    for i in range(0, len(sentence_sources)):\n",
    "        if i == 0 or sentence_sources[i] != sentence_sources[i-1]:\n",
    "            prediction_labels_collapsed.append(prediction_labels[i])\n",
    "            true_labels_collapsed.append(true_labels_flattened[i])\n",
    "        elif prediction_labels[i] != label_values['ANDERS']:\n",
    "            prediction_labels_collapsed[-1] = prediction_labels[i]\n",
    "    return [ true_labels_collapsed, prediction_labels_collapsed ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a47d555-6943-4f6d-ad0c-ed98ae2afe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_ids(sentences, file_labels, keep_short_only=False):\n",
    "    input_ids, attention_masks, expanded_labels, sentence_sources = [], [], [], []\n",
    "    max_length = 64\n",
    "    for i in range(0, len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        while len(sentence) > 0:\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                                sentence,\n",
    "                                max_length = max_length,\n",
    "                                truncation=True,\n",
    "                                padding='max_length',\n",
    "                                add_special_tokens = True,\n",
    "                                return_attention_mask = True,\n",
    "                                return_tensors = 'pt',\n",
    "                           )\n",
    "            if keep_short_only and encoded_dict['attention_mask'][0][max_length-1] != 0:\n",
    "                break\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "            expanded_labels.append(file_labels[i])\n",
    "            sentence_sources.append(i)\n",
    "            sentence = remove_initial_words(sentence, int(max_length/2))\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(expanded_labels)\n",
    "    return [input_ids, attention_masks, labels, sentence_sources]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f4b276e-439a-46d4-9a95-c8c191034069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(fold, sentences):\n",
    "    validation_start = int(0.1 * fold * len(sentences))\n",
    "    validation_end = int(0.1 * (fold + 1) * len(sentences))\n",
    "    input_ids, attention_masks, labels, sentence_sources_validation = make_input_ids(sentences[validation_start:validation_end], \n",
    "                                                                                     file_labels[validation_start:validation_end], \n",
    "                                                                                     keep_short_only=False)\n",
    "    val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    if fold == 0:\n",
    "        training_sentences = []\n",
    "        training_file_labels = []\n",
    "    else:\n",
    "        training_sentences = sentences[:validation_start]\n",
    "        training_file_labels = file_labels[:validation_start]\n",
    "    if fold < 9:\n",
    "        training_sentences.extend(sentences[validation_end:])\n",
    "        training_file_labels.extend(file_labels[validation_end:])\n",
    "    input_ids, attention_masks, labels, _ = make_input_ids(training_sentences, training_file_labels, keep_short_only=True)\n",
    "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    return [ train_dataset, val_dataset, sentence_sources_validation ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62ccf8c4-c65b-481d-adf9-940ea4fb4179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_experiment(fold, sentences):\n",
    "    train_dataset, val_dataset, sentence_sources_validation = make_data(fold, sentences)\n",
    "    print(f\"fold: {fold}; train size: {len(train_dataset)}; validation size: {len(val_dataset)}\")\n",
    "    batch_size = 32\n",
    "    train_dataloader = DataLoader(\n",
    "                train_dataset,\n",
    "                sampler = RandomSampler(train_dataset),\n",
    "                batch_size = batch_size\n",
    "            )\n",
    "    validation_dataloader = DataLoader(\n",
    "                val_dataset,\n",
    "                sampler = SequentialSampler(val_dataset),\n",
    "                batch_size = batch_size\n",
    "            )\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                      lr = 2e-5,\n",
    "                      eps = 1e-8\n",
    "                    )\n",
    "    epochs = 2\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                num_warmup_steps = 0,\n",
    "                                                num_training_steps = total_steps)\n",
    "    return [ train_dataset, val_dataset, train_dataloader, validation_dataloader, batch_size, epochs, total_steps, optimizer, scheduler, sentence_sources_validation ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dad24be6-e116-43d7-a299-72a5083768a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, device, optimizer, scheduler):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 10 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}    Loss: {:.3f}.'.format(step, len(train_dataloader), elapsed, total_train_loss/step))\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].long().to(device)\n",
    "        model.zero_grad()        \n",
    "        model_output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = model_output[\"loss\"]\n",
    "        logits = model_output[\"logits\"]\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "    return avg_train_loss, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2d8bf75-aaad-4096-8690-503439bd03c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, validation_dataloader, device, sentence_sources_validation, label_values):\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    logits_total, label_ids_total = [], []\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        with torch.no_grad():        \n",
    "            model_output = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = model_output[\"loss\"]\n",
    "        logits = model_output[\"logits\"]\n",
    "        total_eval_loss += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        logits_total.append(logits)\n",
    "        label_ids_total.append(label_ids)\n",
    "    true_labels_collapsed, prediction_labels_collapsed = collapse_labels(label_ids_total, logits_total, sentence_sources_validation, label_values)\n",
    "    print(confusion_matrix(true_labels_collapsed, prediction_labels_collapsed))\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(avg_val_accuracy))\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    print(\"  Validation Loss: {0:.3f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "    return [ avg_val_accuracy, avg_val_loss, validation_time, true_labels_collapsed, prediction_labels_collapsed ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6df104-d12d-4f7b-b8c6-e9ecb3254e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af5bc4f5-af69-4eb2-a837-e5b7a301535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 2\n",
    "sentences = [ 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten' ]\n",
    "file_labels = [ [1], [0], [1], [0], [1], [0], [1], [0], [1], [0] ]\n",
    "label_values = { \"odd\": 1, \"even\": 0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14e36416-422c-45c8-8ca6-fbb0ddca545a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pdelobelle/robbert-v2-dutch-base were not used when initializing RobertaForTokenClassification: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0; train size: 9; validation size: 1\n",
      "======== Fold  0 ============\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (576) must match the size of tensor b (9) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15783/308732605.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"======== Fold {fold:2d} ============\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mavg_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mavg_val_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels_collapsed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_labels_collapsed\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_sources_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15783/2700684175.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, device, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     18\u001b[0m                              \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                              \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                              labels=b_labels)\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 \u001b[0mactive_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m                 active_labels = torch.where(\n\u001b[0;32m-> 1389\u001b[0;31m                     \u001b[0mactive_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m                 )\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (576) must match the size of tensor b (9) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "for fold in range(0, 1):\n",
    "    model = RobertaForTokenClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\", num_labels = num_labels)\n",
    "    train_dataset, val_dataset, train_dataloader, validation_dataloader, batch_size, epochs, total_steps, optimizer, scheduler, sentence_sources_validation = \\\n",
    "        make_experiment(fold, sentences)\n",
    "    seed_val = 42\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    if torch.cuda.is_available():\n",
    "         torch.cuda.manual_seed_all(seed_val)\n",
    "    training_stats = []\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"======== Fold {fold:2d} ============\")\n",
    "    for epoch_i in range(0, epochs):\n",
    "        avg_train_loss, training_time = train_model(model, train_dataloader, device, optimizer, scheduler)\n",
    "        avg_val_accuracy, avg_val_loss, validation_time, true_labels_collapsed, prediction_labels_collapsed = \\\n",
    "            validate_model(model, validation_dataloader, device, sentence_sources_validation, label_values)\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Valid. Accur.': avg_val_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "    true_labels.extend(true_labels_collapsed)\n",
    "    predicted_labels.extend(prediction_labels_collapsed)\n",
    "    print(\"\")\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58febb36-7093-4162-b408-670f9ae42aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa62c33115a444c59b999b2bdec72807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/657M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 13:20:29.608150: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-09-13 13:20:29.608933: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-13 13:20:29.609891: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (eslt0070): /proc/driver/nvidia/version does not exist\n",
      "2021-09-13 13:20:29.614158: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-13 13:20:29.759095: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "2021-09-13 13:20:30.118979: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "2021-09-13 13:20:30.144443: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "2021-09-13 13:20:31.742526: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "All model checkpoint layers were used when initializing TFRobertaForTokenClassification.\n",
      "\n",
      "Some layers of TFRobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, TFRobertaForTokenClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = TFRobertaForTokenClassification.from_pretrained('roberta-base')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "inputs[\"labels\"] = tf.reshape(tf.constant([1] * tf.size(input_ids).numpy()), (-1, tf.size(input_ids))) # Batch size 1\n",
    "\n",
    "outputs = model(inputs)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c17aff83-a21d-4f3f-ab8d-9b31a63af473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFTokenClassifierOutput(loss=<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       "array([0.96366346, 0.8813128 , 0.8159864 , 0.9368043 , 0.8876237 ,\n",
       "       0.9718523 , 0.9483712 , 0.9594501 ], dtype=float32)>, logits=<tf.Tensor: shape=(1, 8, 2), dtype=float32, numpy=\n",
       "array([[[ 0.21698526, -0.26623178],\n",
       "        [ 0.22669883, -0.11977093],\n",
       "        [ 0.19018662, -0.0420396 ],\n",
       "        [ 0.29770395, -0.14172032],\n",
       "        [ 0.27932957, -0.07789023],\n",
       "        [ 0.34191462, -0.15450892],\n",
       "        [ 0.27515537, -0.18321918],\n",
       "        [ 0.20966242, -0.26673368]]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca33e8-8e5b-46b6-b734-6cf882187611",
   "metadata": {},
   "source": [
    "## 9. Tutorial example for Token Classification (transformers)\n",
    "\n",
    "Source: looks like https://huggingface.co/transformers/usage.html#named-entity-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6b8ed163-eb3b-46ef-a1c0-05eb8fa8a9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "sequence = \"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, \" \\\n",
    "           \"therefore very close to the Manhattan Bridge.\"\n",
    "\n",
    "inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "tokens = inputs.tokens()\n",
    "\n",
    "outputs = model(**inputs).logits\n",
    "predictions = torch.argmax(outputs, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "73085c17-2330-4443-8073-834c06b2982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[CLS]', 'O')\n",
      "('Hu', 'I-ORG')\n",
      "('##gging', 'I-ORG')\n",
      "('Face', 'I-ORG')\n",
      "('Inc', 'I-ORG')\n",
      "('.', 'O')\n",
      "('is', 'O')\n",
      "('a', 'O')\n",
      "('company', 'O')\n",
      "('based', 'O')\n",
      "('in', 'O')\n",
      "('New', 'I-LOC')\n",
      "('York', 'I-LOC')\n",
      "('City', 'I-LOC')\n",
      "('.', 'O')\n",
      "('Its', 'O')\n",
      "('headquarters', 'O')\n",
      "('are', 'O')\n",
      "('in', 'O')\n",
      "('D', 'I-LOC')\n",
      "('##UM', 'I-LOC')\n",
      "('##BO', 'I-LOC')\n",
      "(',', 'O')\n",
      "('therefore', 'O')\n",
      "('very', 'O')\n",
      "('close', 'O')\n",
      "('to', 'O')\n",
      "('the', 'O')\n",
      "('Manhattan', 'I-LOC')\n",
      "('Bridge', 'I-LOC')\n",
      "('.', 'O')\n",
      "('[SEP]', 'O')\n"
     ]
    }
   ],
   "source": [
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, model.config.id2label[prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184e53a5-a87f-4429-beaf-f06515eff4bc",
   "metadata": {},
   "source": [
    "## 10. Tutorial example for Token Classification (BERT)\n",
    "\n",
    "Source: https://huggingface.co/transformers/model_doc/bert.html#bertfortokenclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed78556a-c1eb-4d56-97c3-72323eac5ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute, he lives in New York\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1] * inputs[\"input_ids\"].size(1)).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b0f2139-498e-4700-8ff7-c0242ce6f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2list(tensor_data):\n",
    "    return [int(x) for x in list(tensor_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fd66fa4-f573-4536-8c8e-4e5d386ede0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\n",
      "hello\n",
      ",\n",
      "my\n",
      "dog\n",
      "is\n",
      "cute\n",
      ",\n",
      "he\n",
      "lives\n",
      "in\n",
      "new\n",
      "york\n",
      "[SEP]\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for token_id in tensor2list(inputs[\"input_ids\"][0]):\n",
    "    tokens.append(tokenizer.decode([token_id]))\n",
    "    print(tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d37c0b8-a27f-4304-b127-6797eae441ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.argmax(logits, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ddf50b6-b57a-4018-a6be-a1dd56c86ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[CLS]', 'LABEL_1')\n",
      "('hello', 'LABEL_1')\n",
      "(',', 'LABEL_0')\n",
      "('my', 'LABEL_0')\n",
      "('dog', 'LABEL_1')\n",
      "('is', 'LABEL_1')\n",
      "('cute', 'LABEL_0')\n",
      "(',', 'LABEL_0')\n",
      "('he', 'LABEL_0')\n",
      "('lives', 'LABEL_0')\n",
      "('in', 'LABEL_1')\n",
      "('new', 'LABEL_1')\n",
      "('york', 'LABEL_1')\n",
      "('[SEP]', 'LABEL_1')\n"
     ]
    }
   ],
   "source": [
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, model.config.id2label[prediction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be6d3d00-a36c-47ff-a734-c93b8465ef0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef47a714-630b-4c41-8090-c294b15509bd",
   "metadata": {},
   "source": [
    "## 11. BERT (Huggingface) fine-tuning by Ashwin Ambal\n",
    "\n",
    "Source: https://colab.research.google.com/drive/1JxWdw1BjXZCFC2a8IwtZxvvq4rFGcxas\n",
    "\n",
    "See also: https://github.com/huggingface/transformers/issues/328"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99969d26-d726-449e-a00c-e4c870db52b4",
   "metadata": {},
   "source": [
    "## 12. BERT for Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe254813-6aa2-4166-b21c-c1e2b9cc86aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68da8e54-491a-4b1e-b681-997dcecfea86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4472d14-94cc-40c0-86ac-9690165bd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.argmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17b962b9-17d6-481e-805d-05f6bd061546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e184e45-7c8d-4c6d-914a-b12edbc2e40e",
   "metadata": {},
   "source": [
    "## 13. Roberta for token classification, from manual\n",
    "\n",
    "Source: https://huggingface.co/transformers/model_doc/roberta.html#robertafortokenclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a330f51-debe-46c4-bbb9-cecf324f0ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForTokenClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForTokenClassification.from_pretrained('roberta-base')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute, he lives in New York\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1] * inputs[\"input_ids\"].size(1)).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42ccc0fa-0a34-40e8-936f-9f25cc2cd08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c03da5b-0f6f-4096-aa7a-4e6701ae6548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "Hello\n",
      ",\n",
      " my\n",
      " dog\n",
      " is\n",
      " cute\n",
      ",\n",
      " he\n",
      " lives\n",
      " in\n",
      " New\n",
      " York\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for token_id in tensor2list(inputs[\"input_ids\"][0]):\n",
    "    tokens.append(tokenizer.decode([token_id]))\n",
    "    print(tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5bad3a84-fcec-4c1b-a448-8e45722deeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.argmax(logits, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7828fec0-062f-48f9-9356-0a0c11310bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', 'LABEL_1')\n",
      "('Hello', 'LABEL_1')\n",
      "(',', 'LABEL_1')\n",
      "(' my', 'LABEL_1')\n",
      "(' dog', 'LABEL_1')\n",
      "(' is', 'LABEL_1')\n",
      "(' cute', 'LABEL_1')\n",
      "(',', 'LABEL_1')\n",
      "(' he', 'LABEL_1')\n",
      "(' lives', 'LABEL_1')\n",
      "(' in', 'LABEL_1')\n",
      "(' New', 'LABEL_1')\n",
      "(' York', 'LABEL_1')\n",
      "('</s>', 'LABEL_1')\n"
     ]
    }
   ],
   "source": [
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, model.config.id2label[prediction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b65bcf41-b08d-4d10-8f92-4b53ec9b64da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9ad06d-d434-4536-a461-0583eafdbc8d",
   "metadata": {},
   "source": [
    "## 14. Roberta Named Entity Recogntion by Erik Novak\n",
    "\n",
    "Source: https://www.kaggle.com/eriknovak/pytorch-roberta-named-entity-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da97782c-fce1-4b58-82ce-a8314c8211eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (1.6.2)\n",
      "Collecting tqdm<4.50.0,>=4.27\n",
      "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<0.1.0 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from datasets) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from datasets) (4.0.0)\n",
      "Requirement already satisfied: pandas in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from datasets) (0.25.1)\n",
      "Requirement already satisfied: xxhash in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: packaging in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from datasets) (19.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: dill in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: fsspec in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from datasets) (0.5.2)\n",
      "Requirement already satisfied: filelock in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from importlib-metadata->datasets) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata->datasets) (7.2.0)\n",
      "Requirement already satisfied: six in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from packaging->datasets) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from packaging->datasets) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from pandas->datasets) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/erikt/anaconda3/envs/python37/lib/python3.7/site-packages (from pandas->datasets) (2019.3)\n",
      "Installing collected packages: tqdm\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.61.0\n",
      "    Uninstalling tqdm-4.61.0:\n",
      "      Successfully uninstalled tqdm-4.61.0\n",
      "Successfully installed tqdm-4.49.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/erikt/anaconda3/envs/python37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6a544a-3a56-498c-a765-59cbc0bdf757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# pytorch libraries\n",
    "import torch # the main pytorch library\n",
    "import torch.nn as nn # the sub-library containing Softmax, Module and other useful functions\n",
    "import torch.optim as optim # the sub-library containing the common optimizers (SGD, Adam, etc.)\n",
    "\n",
    "# huggingface's transformers library\n",
    "from transformers import RobertaForTokenClassification, RobertaTokenizer\n",
    "\n",
    "# huggingface's datasets library\n",
    "from datasets import load_dataset \n",
    "# HACK for transformers kernel: in ~/projects/filterbubble/transformers/venv3/lib/python3.7/site-packages/datasets/load.py replaced line 284: huggingface_hub.hf_api.DatasetInfo by \"\"\n",
    "\n",
    "# the tqdm library used to show the iteration progress\n",
    "import tqdm\n",
    "tqdmn = tqdm.notebook.tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37b4dd9f-c48d-4aa4-9bff-225556243f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2861d046aba4d459eac4735c9a36722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7f82c0f77141658f273bed60817d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "roberta_version = 'roberta-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(roberta_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf84a40e-c9ec-48b8-953a-485782b985fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/home/erikt/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58297d01-ee9d-4f4c-8978-697f2efc2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = dataset['train'].features['ner_tags'].feature.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "511be672-aa2c-4c1c-8cd8-d7691bfec088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_encodings(example):\n",
    "    \"\"\"Processing the example\n",
    "    \n",
    "    Args:\n",
    "        example (dict): The dataset example.\n",
    "    \n",
    "    Returns:\n",
    "        dict: The dictionary containing the following updates:\n",
    "            - input_ids: The list of input ids of the tokens.\n",
    "            - attention_mask: The attention mask list.\n",
    "            - ner_tags: The updated ner_tags.\n",
    "    \n",
    "    \"\"\"\n",
    "    # get the encodings of the tokens. The tokens are already split, that is why we must add is_split_into_words=True\n",
    "    encodings = tokenizer(example['tokens'], truncation=True, padding='max_length', is_split_into_words=True)\n",
    "    # extend the ner_tags so that it matches the max_length of the input_ids\n",
    "    labels = example['ner_tags'] + [0] * (tokenizer.model_max_length - len(example['ner_tags']))\n",
    "    # return the encodings and the extended ner_tags\n",
    "    return { **encodings, 'labels': labels }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe64875a-8ed5-4bab-9c9f-cfa46af19598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caac54d3800b4b8cbfcccbbf578b7699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14041.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7742374a8b84482aee3007010983885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecb92e5cc474aac8e733f99f232ddf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3453.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(add_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31ac19bc-7942-4f47-b0b6-aef3d6d429ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58fa9489-38bf-4f06-8e3b-265f1d83c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset['train'].features['ner_tags'].feature\n",
    "label2id = { k: labels.str2int(k) for k in labels.names }\n",
    "id2label = { v: k for k, v in label2id.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4511db30-c122-4c32-a61a-ed5956f96e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66510147fa5442c8d58c8b78e32f25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3c0d6569004e87936d9ea2da37c604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# initialize the model and provide the 'num_labels' used to create the classification layer\n",
    "model = RobertaForTokenClassification.from_pretrained(roberta_version, num_labels=num_labels)\n",
    "# assign the 'id2label' and 'label2id' model configs\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ff2c528-1eea-431d-9cfd-a5fa53002b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52c9bf40-4a07-4141-bc84-638d0998a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train().to(device)\n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb547280-225b-493b-b540-808e488e77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "train_data = torch.utils.data.DataLoader(dataset['train'], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d290f1d-7124-4792-8036-37fe7b9c185f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6dad7b365f499fbff43d5478ae4313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca453f20ed443c7becf6ff587fe5ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3511.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a604e05d2a4eeb898728cfa5b9deff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3511.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b20b042fe6456c9acd2bf4faadd930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3511.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "# iterate through the data 'n_epochs' times\n",
    "for epoch in tqdmn(range(n_epochs)):\n",
    "    current_loss = 0\n",
    "    # iterate through each batch of the train data\n",
    "    for i, batch in enumerate(tqdmn(train_data)):\n",
    "        if i >= 10: # partial train\n",
    "            break   # partial train\n",
    "        # move the batch tensors to the same device as the \n",
    "        batch = { k: v.to(device) for k, v in batch.items() }\n",
    "        # send 'input_ids', 'attention_mask' and 'labels' to the model\n",
    "        outputs = model(**batch)\n",
    "        # the outputs are of shape (loss, logits)\n",
    "        loss = outputs[0]\n",
    "        # with the .backward method it calculates all \n",
    "        # of  the gradients used for autograd\n",
    "        loss.backward()\n",
    "        # NOTE: if we append `loss` (a tensor) we will force the GPU to save\n",
    "        # the loss into its memory, potentially filling it up. To avoid this\n",
    "        # we rather store its float value, which can be accessed through the\n",
    "        # `.item` method\n",
    "        current_loss += loss.item()\n",
    "        if i % 8 == 0 and i > 0:\n",
    "            # update the model using the optimizer\n",
    "            optimizer.step()\n",
    "            # once we update the model we set the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            # store the loss value for visualization\n",
    "            train_loss.append(current_loss / 32)\n",
    "            current_loss = 0\n",
    "    # update the model one last time for this epoch\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "096702a4-fd03-4164-bd64-8039f896591a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "# visualize the loss values\n",
    "ax.plot(train_loss)\n",
    "# set the labels\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Iterations (32 examples)')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8684cae6-8127-4a67-8f81-9c1cc71039d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "# batch the train data so that each batch contains 4 examples (using 'batch_size')\n",
    "test_data = torch.utils.data.DataLoader(dataset['test'], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f1de3b2-cbc6-4a71-9cf9-65ac7fa8f81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fc3c73ed6e49a7b1a1c5395ecba9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=864.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create the confusion matrix\n",
    "confusion = torch.zeros(num_labels, num_labels)\n",
    "\n",
    "# iterate through each batch of the train data\n",
    "for i, batch in enumerate(tqdmn(test_data)):\n",
    "    # do not calculate the gradients\n",
    "    with torch.no_grad():\n",
    "        # move the batch tensors to the same device as the model\n",
    "        batch = { k: v.to(device) for k, v in batch.items() }\n",
    "        # send 'input_ids', 'attention_mask' and 'labels' to the model\n",
    "        outputs = model(**batch)\n",
    "            \n",
    "    # get the sentence lengths\n",
    "    s_lengths = batch['attention_mask'].sum(dim=1)\n",
    "    # iterate through the examples\n",
    "    for idx, length in enumerate(s_lengths):\n",
    "        # get the true values\n",
    "        true_values = batch['labels'][idx][:length]\n",
    "        # get the predicted values\n",
    "        pred_values = torch.argmax(outputs[1], dim=2)[idx][:length]\n",
    "        # go through all true and predicted values and store them in the confusion matrix\n",
    "        for true, pred in zip(true_values, pred_values):\n",
    "            confusion[true.item()][pred.item()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f74eac4d-f8a3-4f2b-b735-ed4627638468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by dividing every row by its sum\n",
    "for i in range(num_labels):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f6f70bf-0aee-4275-a583-1700cf333558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# visualize the loss values\n",
    "ax.matshow(confusion.numpy())\n",
    "\n",
    "# get the labels\n",
    "labels = list(label2id.keys())\n",
    "ids = np.arange(len(labels))\n",
    "\n",
    "ax.set_ylabel('True Labels', fontsize='x-large')\n",
    "ax.set_xlabel('Pred Labels', fontsize='x-large')\n",
    "\n",
    "# set the x ticks\n",
    "ax.set_xticks(ids)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "# set the y ticks\n",
    "ax.set_yticks(ids)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "# plot figure\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59197c99-f4a7-4af6-9271-2d15f2907661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
